# Handling Missing data {#missingdata}

```{r echo = FALSE}
knitr::opts_chunk$set(fig.width = 5, fig.height = 5,
                      comment = NA, cache = F) 
options(rt.theme = "lightgrid")
options(rt.fit.theme = "lightgrid")
```

```{r, comment="", results="asis", echo=FALSE}
old.hooks <- fansi::set_knit_hooks(knitr::knit_hooks)
options(crayon.enabled = TRUE)
```

Missing data is a very common issue in statistics and data science.

Data may be missing for a variety of reasons. We often characterize the type of missingness using the following three types [@mack2018managing]:

-   **Missing completely at random (MCAR)**: "The fact that the data are missing is independent of the observed and unobserved data"
-   **Missing at random (MAR)**: "The fact that the data are missing is systematically related to the observed but not the unobserved data"
-   **Missing not at random (MNAR)**: "The fact that the data are missing is systematically related to the unobserved data"

## Check for missing data

You can use your favorite base R commands to check for missing data, count NA elements by row, by column, total, etc.

Let's load the `PimaIndiansDiabetes2` dataset from the **mlbench** package and make a copy of it to variable `dat`. Remember to check the class of a new object you didn't create yourself with `class()`, check its dimensions, if applicable, with `dim()`, and a get a summary of its structure including data types with `str()`:

```{r}
data("PimaIndiansDiabetes2", package = "mlbench")
dat <- PimaIndiansDiabetes2
class(dat)
dim(dat)
str(dat)
```

Check if there are any missing values in the data.frame with `anyNA()`:

```{r}
anyNA(dat)
```

The above suggests there is one or more `NA` values in the dataset.

We can create a logical index of NA values using `is.na()`. Remember that the output of `is.na()` is a logical matrix with the same dimensions as the dataset:

```{r}
na_index <- is.na(dat)
dim(na_index)
head(na_index)
```

One way to count missing values is with `sum(is.na())`. Remember that a logical array is coerced to an integer array for mathematical operations, where `TRUE` becomes 1 and `FALSE` becomes 0. Therefore, calling `sum()` on a logical index counts the number of `TRUE` elements (and since we are applying it on the index of `NA` values, it counts the number of elements with missing values):

```{r}
sum(is.na(dat))
```

There are 652 `NA` values in total in the data.frame.

Let's count the number of missing values per feature, i.e. per column, using \[`sapply()`\](#sapply):

```{r}
sapply(dat, function(i) sum(is.na(i)))
```

The features `insulin` and `triceps` have the most NA values.

Let's count the number of missing values per case (i.e. row):

```{r}
sapply(1:nrow(dat), function(i) sum(is.na(dat[i, ])))
```

If we wanted to get the row with the most missing values, we can use `which.max()`:

```{r}
which.max(sapply(1:nrow(dat), function(i) sum(is.na(dat[i, ]))))
```

```{r}
sum(is.na(dat[50, ]))
```

Row 50 has 4 missing values.

### Visualize

It may be helpful to visualize missing data to get a quick impression of missingness. The [**rtemis**](https://rtemis.lambdamd.org/) package includes the function `mplot3.missing()`:

```{r}
library(rtemis)
mplot3.missing(dat)
```

Missing data is shown in magenta by default. The row below the image shows total `NA` values per column

### Summarize

Get N of missing per column:

```{r}
sapply(dat, function(i) sum(is.na(i)))
```

`rtemis::checkData()` includes information on missing data:

```{r}
checkData(dat)
```

## Handle missing data

Different approaches can be used to handle missing data:

-   Do nothing - if your algorithm(s) can handle missing data (decision trees!)
-   **Exclude** data: Use complete cases only
-   **Fill in** (make up) data: Replace or Impute
    -   Replace with median/mean
    -   Predict missing from present
        -   Single imputation
        -   Multiple imputation

### Do nothing

Algorithms like decision trees and ensemble methods that use decision trees like random forest and gradient boosting can handle missing data, depending on the particular implementation. For example, `rpart::rpart()` which is used by `rtemis::s.CART()` has no trouble with missing data in the predictors:

```{r}
dat.cart <- s.CART(dat)
```

### Use complete cases only

R's builtin `complete.cases()` function returns, as the name suggests, a logical index of cases (i.e. rows) that have no missing values, i.e. are complete.

```{r}
dim(dat)
index_cc <- complete.cases(dat)
class(index_cc)
length(index_cc)
head(index_cc)
dat_cc <- dat[index_cc, ]
dim(dat_cc)
```

We lost `r nrow(dat) - nrow(dat_cc)` cases in the above example. That's quite a few, so, for this dataset, we probably want to look at options that do not exclude cases.

### Replace with a fixed value

We can manually replace missing values with the mean or median in the case of a continuous variable, or with the mode in the case of a categorical feature.\
For example, to replace the first feature's missing values with the mean:

```{r}
pressure_mean <- mean(dat$pressure, na.rm = TRUE)
dat_im <- dat
dat_im$pressure[is.na(dat_im$pressure)] <- pressure_mean
```

`rtemis::preprocess()` can replace missing values with mean (for numeric features) and the mode (for factors) for all columns:

```{r}
dat_pre <- preprocess(dat, impute = TRUE, impute.type = "meanMode")
```

Verify there are no missing data by rerunning `checkData()`:

```{r}
checkData(dat_pre)
```

You may want to include a "missingness" column that indicates which cases were imputed to include in your model. You can create this simply by running:

```{r}
pressure_missing = factor(as.integer(is.na(dat$pressure)))
```

`preprocess()` includes the option `missingness` to add indicator columns after imputation:

```{r}
dat_pre <- preprocess(dat, impute = TRUE, impute.type = "meanMode",
                      missingness = TRUE)
head(dat_pre)
```

#### Add new level "missing"

One option to handle missing data in categorical variables, is to introduce a new level of "missing" to the factor, instead of replacing with the mode, for example. If we bin a continuous variable to convert to categorical, the same can then also be applied.

Since no factors have missing values in the current dataset we create a copy and replace some data with `NA`:

```{r}
dat2 <- dat
dat2$diabetes[sample(1:NROW(dat2), 35)] <- NA
sum(is.na(dat2$diabetes))
levels(dat2$diabetes)
```

Replace `NA` values with new level `missing`:

```{r}
dat_pre2 <- preprocess(dat2, factorNA2missing = TRUE)
anyNA(dat_pre2$diabetes)
levels(dat_pre2$diabetes)
```

### Last observation carried forward (LOCF)

In longitudinal / timeseries data, we may want to replace missing values with the last observed value. This is called last observation carried forward (LOCF). As always, whether this procedure is appropriate depend the reasons for missingness. The `zoo` and `DescTool` packages provide commands to perform LOCF.

Some simulated data. We are missing blood pressure measurements on Saturdays and Sundays:

```{r}
dat <- data.frame(Day = rep(c("Mon", "Tues", "Wed", "Thu", "Fri", "Sat", "Sun"), 3),
                  SBP = sample(105:125, 21, TRUE))
dat$SBP[dat$Day == "Sat" | dat$Day == "Sun"] <- NA
dat
```

The **zoo** package includes the `na.locf()`.

```{r}
dat$SBPlocf <- zoo::na.locf(dat$SBP)
dat
```

Similar functionality is included in **DescTools**' `LOCF()` function:

```{r}
DescTools::LOCF(dat$SBP)
```

### Replace missing values with estimated values

#### Single imputation

You can use non-missing data to predict missing data in an iterative procedure \[@buuren2010mice\]\[@stekhoven2012missforest\]. The `missRanger` package uses the optimized (and parallel-capable) package `ranger` [@wright2015ranger] to iteratively train random forest models for imputation.

```{r}
library(missRanger)
dat <- iris
set.seed(2020)
dat[sample(1:150, 5), 1] <- dat[sample(1:150, 22), 4] <- dat[sample(1:150, 18), 4] <- NA
dat_rfimp <- missRanger(dat, num.trees = 100)
head(dat_rfimp)
checkData(dat_rfimp)
```

Note: The default method for `preprocess(impute = TRUE)` is to use `missRanger`.

#### Multiple imputation

Multiple imputation creates multiple estimates of the missing data. It is more statistically valid for small datasets, especially when the goal is to get accurate estimates of a summary statistics, but may not be practical for larger datasets. It is not usually considered an option for machine learning (where duplicating cases may add bias and complexity in resampling). The package `mice` is a popular choice for multiple imputation in R.

```{r eval = FALSE}
library(mice)
dat_mice <- mice(dat)
```
