# Common Statistical Tests {#stats}

```{r echo = FALSE}
knitr::opts_chunk$set(fig.width = 5, fig.height = 5,
                      comment = NA, cache = TRUE)
```

R includes a large number of functions to perform statistical hypothesis testing in the built-in `stats` package. This chapter includes a brief overview of the syntax for some common tests along with code to produce relevant plots of your data.

## Correlation test

```{r}
set.seed(2020)
x <- rnorm(100)
y1 <- 0.1 * x + rnorm(100)
y2 <- 0.3 * x + rnorm(100)
y3 <- x + rnorm(100)/5
y4 <- x^2 + rnorm(100)
```

Scatterplot with linear fit:

```{r}
plot(x, y1,
     col = "#00000077",
     pch = 16, bty = "none")
abline(lm(y1 ~ x), col = "red", lwd = 2)
```

```{r}
plot(x, y2,
     col = "#00000077",
     pch = 16, bty = "none")
abline(lm(y3 ~ x), col = "red", lwd = 2)
```

```{r}
plot(x, y3,
     col = "#00000077",
     pch = 16, bty = "none")
abline(lm(y3 ~ x), col = "red", lwd = 2)
```

Scatterplot with a LOESS fit

```{r}
scatter.smooth(x, y4,
               col = "#00000077",
               pch = 16, bty = "none",
               lpars = list(col = "red", lwd = 2))
```

```{r}
cor.test(x, y1)
cor.test(x, y2)
cor.test(x, y3)
cor.test(x, y4)
```
## Student's t-test

```{r}
set.seed(2021)
x0 <- rnorm(500)
x1 <- rnorm(500, mean = 0.7)
```

For all tests of differences in means, a boxplot is a good way to visualize. It accepts individual vectors, list or data.frame of vectors, or a formula to split a vector into groups by a factor.

```{r}
boxplot(x0, x1,
        col = "#05204999", border = "#052049",
        boxwex = 0.3, names = c("x0", "x1"))
```

### One sample t-test

```{r}
t.test(x0)
```
```{r}
t.test(x1)
```

```{r}
boxplot(extra ~ group, data = sleep,
        col = "#05204999", border = "#052049",
        boxwex = 0.3)
```

### Two-sample T-test

Both `t.test()` and `wilcox.test()` (below) either accept input as two vectors, 
`t.test(x, y)` or a formula of the form `t.test(x ~ group)`. The `paired` argument allows us to define a paired test. Since the `sleep` dataset includes measurements on the same cases in two conditions, we set `paired = TRUE`.

```{r}
t.test(extra ~ group, data = sleep, paired = TRUE)
```

## Wilcoxon test

Data from R Documentation:

```{r}
## Hollander & Wolfe (1973), 29f.
## Hamilton depression scale factor measurements in 9 patients with
##  mixed anxiety and depression, taken at the first (x) and second
##  (y) visit after initiation of a therapy (administration of a
##  tranquilizer).
x <- c(1.83,  0.50,  1.62,  2.48, 1.68, 1.88, 1.55, 3.06, 1.30)
y <- c(0.878, 0.647, 0.598, 2.05, 1.06, 1.29, 1.06, 3.14, 1.29)
depression <- data.frame(first = x, second = y, change = y - x)
```

### One-sample Wilcoxon 

```{r}
wilcox.test(depression$change)
```

### Two-sample Wilcoxon rank sum test (unpaired)

a.k.a Mann-Whitney U test a.k.a. Mann–Whitney–Wilcoxon (MWW) a.k.a. Wilcoxon–Mann–Whitney test

```{r}
x1 <- rnorm(500, mean = 3, sd = 1.5)
x2 <- rnorm(500, mean = 5, sd = 2)
wilcox.test(x1, x2)
```

### Two-sample Wilcoxon signed-rank test (paired)

```{r}
wilcox.test(x, y, paired = TRUE)
```

```{r}
wilcox.test(x, y, paired = TRUE, alternative = "greater")
```

## Analysis of Variance

```{r}
set.seed(20)
BP_drug <- data.frame(
  Group = factor(rep(c("Placebo", "Drug_A", "Drug_B"), each = 20),
                 levels = c("Placebo", "Drug_A", "Drug_B")),
    SBP = c(rnorm(20, mean = 140, sd = 2.2), rnorm(20, mean = 132, sd = 2.1),
            rnorm(20, mean = 138, sd = 2))
)
```

```{r}
boxplot(SBP ~ Group, data = BP_drug,
        col = "#05204999", border = "#052049",
        boxwex = 0.3)
```


```{r}
SBP_aov <- aov(SBP ~ Group, data = BP_drug)
SBP_aov
```

```{r}
summary(SBP_aov)
```

The analysis of variance p-value is highly significant, but doesn't tell us which levels of the Group factor are significantly different from each other. The boxplot already gives us a pretty good idea, but we can follow up with a pairwise t-test 

### Pot-hoc pairwise t-tests

```{r}
pairwise.t.test(BP_drug$SBP, BP_drug$Group,
                p.adj = "holm")
```

The pairwise tests suggest that the difference between Placebo and Drug_A and between Drug_a and Drug_b are highly significant, while difference between Placebo and Drub_B is not (p = 0.065).

## Kruskal-Wallis test

Kruskal-Wallis rank sum test of the null that the location parameters of the distribution of x are the same in each group (sample). The alternative is that they differ in at least one. It is a generalization of the Wilcoxon test to multiple independent samples.

From the R Documentation:

```{r}
## Hollander & Wolfe (1973), 116.
## Mucociliary efficiency from the rate of removal of dust in normal
##  subjects, subjects with obstructive airway disease, and subjects
##  with asbestosis.
x <- c(2.9, 3.0, 2.5, 2.6, 3.2) # normal subjects
y <- c(3.8, 2.7, 4.0, 2.4)      # with obstructive airway disease
z <- c(2.8, 3.4, 3.7, 2.2, 2.0) # with asbestosis
kruskal.test(list(x, y, z))
```

```{r}
boxplot(Ozone ~ Month, data = airquality,
        col = "#05204999", border = "#052049",
        boxwex = 0.3)
```

```{r}
kruskal.test(Ozone ~ Month, data = airquality)
```

## Chi-squared Test

Pearson's chi-squared test for count data

Some synthetic data:

```{r}
set.seed(2021)
set.seed(2021)
Cohort <- factor(sample(c("Control", "Case"), size = 500, replace = TRUE),
                 levels = c("Control", "Case"))
Sex <- factor(
  sapply(seq(Cohort), \(i) sample(c("Male", "Female"), size = 1,
                                  prob = if (Cohort[i] == "Control") c(1, 1) else c(2, 1))))
dat <- data.frame(Cohort, Sex)
head(dat)
```

You can lot count data using a [mosaic plot](#mosaicplot), with either a table or formula input:

```{r}
mosaicplot(table(Cohort, Sex),
           color = c("orchid", "skyblue"),
           border = NA,
           main = "Cohort x Sex")
```

```{r}
mosaicplot(Cohort ~ Sex, dat,
           color = c("orchid", "skyblue"),
           border = NA,
           main = "Cohort x Sex")
```

`chisq.test()` accepts either two factors, or a table:

```{r}
cohort_sex_chisq <- chisq.test(dat$Cohort, dat$Sex)
cohort_sex_chisq
```

```{r}
cohort_sex_chisq <- chisq.test(table(dat$Cohort, dat$Sex))
cohort_sex_chisq
```


## Fisher's exact test

Fisher's exact test for count data

Working on the same data as above, `fisher.test()` also accepts either two factors or a table as input:

```{r}
cohort_sex_fisher <- fisher.test(dat$Cohort, dat$Sex)
cohort_sex_fisher
```

```{r}
cohort_sex_fisher <- fisher.test(table(dat$Cohort, dat$Sex))
cohort_sex_fisher
```

## F Test to compare two variances

```{r}
x1 <- rnorm(500, sd = 1)
x2 <- rnorm(400, sd = 1.5)
var.test(x1, x2)
```

```{r}
boxplot(x1, x2,
        col = "#05204999", border = "#052049",
        boxwex = 0.3)
```

From R Documentation:

```{r}
x <- rnorm(50, mean = 0, sd = 2)
y <- rnorm(30, mean = 1, sd = 1)
var.test(x, y)                  # Do x and y have the same variance?
var.test(lm(x ~ 1), lm(y ~ 1))  # same
```

## Bartlett test of homogeneity of variances

Performs Bartlett's test of the null that the variances in each of the groups (samples) are the same.

From the R Documentation:

```{r}
plot(count ~ spray, data = InsectSprays)
```

```{r}
bartlett.test(InsectSprays$count, InsectSprays$spray)
```

```{r}
bartlett.test(count ~ spray, data = InsectSprays)
```

## Fligner-Killeen test of homogeneity of variances

Performs a Fligner-Killeen (median) test of the 
null that the variances in each of the groups (samples) are the same.

```{r}
boxplot(count ~ spray, data = InsectSprays)
# works the same if you do plot(count ~ spray, data = InsectSprays)
fligner.test(InsectSprays$count, InsectSprays$spray)
fligner.test(count ~ spray, data = InsectSprays)
```

## Ansari-Bradley test

Performs the Ansari-Bradley two-sample test for a difference in scale parameters.

```{r}
ramsay <- c(111, 107, 100, 99, 102, 106, 109, 108, 104, 99,
            101, 96, 97, 102, 107, 113, 116, 113, 110, 98)
jung.parekh <- c(107, 108, 106, 98, 105, 103, 110, 105, 104,
            100, 96, 108, 103, 104, 114, 114, 113, 108, 106, 99)
ansari.test(ramsay, jung.parekh)
```

```{r}
x <- rnorm(40, sd = 1.5)
y <- rnorm(40, sd = 2.5)
ansari.test(x, y)
```

## Mood two-sample test of scale

```{r}
mood.test(x, y)
```

## Kolmogorov-Smirnoff test

Perform a one- or two-sample Kolmogorov-Smirnov test
Null: x and y were drawn from the same continuous distribution.

```{r}
x1 <- rnorm(200, mean = 0, sd = 1)
x2 <- rnorm(200, mean = -0.5, sd = 1.5)
ks.test(x1, x2)
```

## Shapiro-Wilk test of normality

```{r}
set.seed(2021)
x <- rnorm(2000)
y1 <- 0.7 * x
y2 <- x + x^3
```

### Q-Q Plot

```{r}
qqplot(rnorm(300), y1, pch = 16, col = "#00000077")
qqline(y1, col = "red", lwd = 2)
```

```{r}
qqplot(rnorm(300), y2, pch = 16, col = "#00000077")
qqline(y2, col = "red", lwd = 2)
```

## Shapiro-Wilk test

```{r}
shapiro.test(y1)
shapiro.test(y2)
```

## Resources {#statsresources}

- [Regression Methods in Biostatistics: Linear, Logistic, Survival, and Repeated Measures Models](https://regression.ucsf.edu/)
