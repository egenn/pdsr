---
execute:
  cache: false
knitr:
  opts_chunk: 
    comment: ''
    fig-width: 4.5
    fig-height: 4.5
    warning: false
---

# Optimization {#optimization}

```{r}
#| echo: false
options(rt.theme = "whitegrid")
```

```{r}
#| echo: false
#| results: asis
old.hooks <- fansi::set_knit_hooks(knitr::knit_hooks)
options(crayon.enabled = TRUE)
```

```{r}
#| echo: false
suppressPackageStartupMessages(library(rtemis))
```

R provides a general purpose optimization tool, `optim()`. You can use it to 
estimate parameters that minimize any defined function.  
Supervised and unsupervised learning involves defining a loss function to 
minimize or an objective function to minimize or maximize.  
To learn how `optim()` works, let's write a simple function that returns linear 
coefficients by minimizing squared error.

## Data

```{r}
set.seed(2020)
x <- sapply(seq(10), function(i) rnorm(500))
y <- 12 + 1.5 * x[, 3] + 3.2 * x[, 7] + 0.5 * x[, 9] + rnorm(500)
```

## GLM (`glm`, `s_GLM`)
```{r}
yx.glm <- glm(y ~ x)
summary(yx.glm)
```

Or, using _rtemis_:

```{r}
mod.glm <- s_GLM(x, y)
```

```{r}
summary(mod.glm$mod)
```

## `optim()`

Basic usage of `optim` to find values of parameters that minimize a function:  

* Define a list of initial parameter values
* Define a loss function whose first argument is the above list of initial 
parameter values
* Pass parameter list and objective function to `optim`

In the following example, we wrap these three steps in a function called 
`linearcoeffs`, which will output the linear coefficients that minimize squared 
error, given a matrix/data.frame of features `x` and an outcome `y`. We also 
specify the optimization method to be used (See `?base::optim` for details):

```{r}
linearcoeffs <- function(x, y, method = "BFGS") {
  
  # 1. List of initial parameter values
  params <- as.list(c(mean(y), rep(0, NCOL(x))))
  names(params) <- c("Intercept", paste0("Coefficient", seq(NCOL(x))))
  
  # 2. Loss function: first argument is parameter list
  loss <- function(params, x, y) {
    estimated <- c(params[[1]] + x %*% unlist(params[-1]))
    mean((y - estimated)^2)
  }
  
  # 3. optim!
  coeffs <- optim(params, loss, x = x, y = y, method = method)
  
  # The values that minimize the loss function are stored in $par
  coeffs$par
}
```

```{r}
coeffs.optim <- linearcoeffs(x, y)
estimated.optim <- cbind(1, x) %*% coeffs.optim
mplot3_fit(y, estimated.optim)
coeffs.glm <- mod.glm$mod$coefficients
estimated.glm <- cbind(1, x) %*% coeffs.glm
mplot3_fit(y, estimated.glm)
```

```{r}
mplot3_fit(coeffs.glm, coeffs.optim)
```
